{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"NetLoom","text":"<p>Network Lab Topology Orchestrator</p> <p>NetLoom is a command-line utility for creating and managing network topologies for educational labs. It automates the provisioning of VirtualBox VMs, network configuration generation, and topology deployment.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Declarative Topology Definition - Define your entire network lab in a single YAML file</li> <li>VirtualBox Integration - Automated VM cloning, network setup, and lifecycle management</li> <li>Template-Based Configuration - Generate networkd, routing, and service configs from Jinja2 templates</li> <li>Multi-Role Support - Configure routers, switches, and hosts with role-specific settings</li> <li>Routing Protocol Support - Built-in support for BIRD and FRR routing daemons with OSPF</li> <li>Config Persistence - Save and restore VM configurations between sessions</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install NetLoom\nuv add netloom\n\n# Deploy a topology\nnetloom --topology lab.yaml init      # Import base VM\nnetloom --topology lab.yaml create    # Create VM clones\nnetloom --topology lab.yaml gen       # Generate configs\nnetloom --topology lab.yaml attach    # Attach configs to VMs\nnetloom --topology lab.yaml start     # Start all VMs\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li> Getting Started</li> </ul> <p>Installation, prerequisites, and your first topology deployment</p> <p> Getting started</p> <ul> <li> CLI Reference</li> </ul> <p>Complete reference for all commands and options</p> <p> Reference</p> <ul> <li> Topology Schema</li> </ul> <p>YAML schema reference for defining network topologies</p> <p> Schema</p> <ul> <li> Architecture</li> </ul> <p>Internal design and component overview</p> <p> Architecture</p> <ul> <li> Configuration</li> </ul> <p>Workdir structure and customization options</p> <p> Configuration</p>"},{"location":"#example-topology","title":"Example Topology","text":"<pre><code>meta:\n  id: \"simple-lab\"\n  name: \"Simple Network Lab\"\n\nlinks:\n  - endpoints: [\"R1\", \"R2\"]\n  - endpoints: [\"R1\", \"H1\"]\n\nnodes:\n  - name: R1\n    role: router\n    interfaces:\n      - ip: \"10.0.1.1/24\"\n      - ip: \"192.168.1.1/24\"\n\n  - name: R2\n    role: router\n    interfaces:\n      - ip: \"10.0.1.2/24\"\n\n  - name: H1\n    role: host\n    interfaces:\n      - ip: \"192.168.1.10/24\"\n        gateway: \"192.168.1.1\"\n</code></pre>"},{"location":"#license","title":"License","text":"<p>NetLoom is open source software. See the GitHub repository for details.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>This document describes NetLoom's internal architecture and design.</p>"},{"location":"architecture/#overview","title":"Overview","text":"<p>NetLoom follows a controller-based architecture with a singleton Application class coordinating multiple specialized controllers. Each controller handles a specific domain of functionality.</p> <pre><code>flowchart TB\n    subgraph CLI[\"CLI Layer (cli.py)\"]\n        commands[Commands: init, create, gen, attach, start, stop, destroy]\n    end\n\n    subgraph App[\"Application (core/application.py)\"]\n        direction LR\n        TC[Topology&lt;br/&gt;Controller]\n        IC[Infrastructure&lt;br/&gt;Controller]\n        CC[Config&lt;br/&gt;Controller]\n        NC[Network&lt;br/&gt;Controller]\n    end\n\n    subgraph External[\"External Systems\"]\n        direction LR\n        VBox[VirtualBox&lt;br/&gt;VBoxManage]\n        Jinja[Jinja2&lt;br/&gt;Templates]\n    end\n\n    CLI --&gt; App\n    App --&gt; External</code></pre>"},{"location":"architecture/#core-components","title":"Core Components","text":""},{"location":"architecture/#application","title":"Application","text":"<p>The <code>Application</code> class (<code>netloom/core/application.py</code>) is the central singleton that:</p> <ul> <li>Manages controller instances (lazy initialization)</li> <li>Provides a shared <code>Console</code> for Rich terminal output</li> <li>Tracks workdir and debug state</li> </ul> <pre><code>app = Application.current()\napp.topology.load(\"lab.yaml\")\napp.infrastructure.create(internal)\n</code></pre> <p>Controllers are accessed as properties and created on first access.</p>"},{"location":"architecture/#controllers","title":"Controllers","text":""},{"location":"architecture/#topologycontroller","title":"TopologyController","text":"<p>Location: <code>netloom/controllers/topology.py</code></p> <p>Handles topology loading and conversion:</p> Method Description <code>load(path)</code> Load and validate a YAML topology file <code>convert(topology, workdir)</code> Convert external topology to internal representation <p>The internal representation adds computed fields like interface names, peer relationships, and merged sysctl settings.</p>"},{"location":"architecture/#infrastructurecontroller","title":"InfrastructureController","text":"<p>Location: <code>netloom/controllers/infrastructure.py</code></p> <p>Manages VirtualBox VM lifecycle:</p> Method Description <code>configure(...)</code> Set VirtualBox settings (basefolder, OVA path, etc.) <code>init(internal, workdir)</code> Import OVA and create golden snapshot <code>create(internal)</code> Create linked clones with config-drives <code>start(internal)</code> Start all VMs <code>stop(internal)</code> Stop all VMs (ACPI shutdown) <code>destroy(internal, destroy_base)</code> Remove VMs (hard shutdown) <code>get_configdrive(node_name)</code> Get config-drive path for a node <p>Internally uses <code>VBoxManage</code> commands for VM operations.</p>"},{"location":"architecture/#configcontroller","title":"ConfigController","text":"<p>Location: <code>netloom/controllers/config.py</code></p> <p>Handles configuration generation and deployment:</p> Method Description <code>list_template_sets()</code> List available template sets <code>generate(internal, template_set)</code> Generate configs using templates <code>attach(internal)</code> Copy configs to VM config-drives <code>save(internal)</code> Pull configs from VMs to host <code>restore(internal)</code> Restore saved configs to staging"},{"location":"architecture/#networkcontroller","title":"NetworkController","text":"<p>Location: <code>netloom/controllers/network.py</code></p> <p>Network-related utilities and calculations.</p>"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#1-topology-loading","title":"1. Topology Loading","text":"<pre><code>YAML File \u2192 TopologyController.load() \u2192 ExternalTopology (Pydantic Model)\n                                             \u2502\n                                             \u25bc\n                    TopologyController.convert() \u2192 InternalTopology\n</code></pre> <p>The external <code>Topology</code> model mirrors the YAML schema. The internal representation adds:</p> <ul> <li>Computed interface names (eth1, eth2, ...)</li> <li>Peer node relationships</li> <li>Merged sysctl settings (defaults + node-specific)</li> <li>Resolved service configurations</li> </ul>"},{"location":"architecture/#2-configuration-generation","title":"2. Configuration Generation","text":"<pre><code>InternalTopology \u2192 ConfigController.generate()\n                          \u2502\n                          \u251c\u2500\u2192 Jinja2 Environment\n                          \u2502       \u2502\n                          \u2502       \u25bc\n                          \u2502   Template Sets (networkd/, services/)\n                          \u2502       \u2502\n                          \u2502       \u25bc\n                          \u2514\u2500\u2192 Generated Files (workdir/configs/&lt;node&gt;/)\n</code></pre>"},{"location":"architecture/#3-vm-deployment","title":"3. VM Deployment","text":"<pre><code>InternalTopology \u2192 InfrastructureController.create()\n                          \u2502\n                          \u251c\u2500\u2192 VBoxManage clonevm (linked clone)\n                          \u251c\u2500\u2192 VBoxManage createmedium (config-drive)\n                          \u2514\u2500\u2192 VBoxManage modifyvm (NICs, hardware)\n</code></pre>"},{"location":"architecture/#models","title":"Models","text":""},{"location":"architecture/#external-models-netloommodelsconfigpy","title":"External Models (<code>netloom/models/config.py</code>)","text":"<p>Pydantic models that match the YAML schema:</p> <ul> <li><code>Topology</code> - Root model</li> <li><code>Meta</code> - Topology metadata</li> <li><code>Defaults</code> - Global defaults</li> <li><code>Link</code> - Node connections</li> <li><code>Node</code> - Node configuration</li> <li><code>InterfaceConfig</code>, <code>BridgeConfig</code>, <code>RoutingConfig</code>, etc.</li> </ul>"},{"location":"architecture/#internal-models-netloommodelsinternalpy","title":"Internal Models (<code>netloom/models/internal.py</code>)","text":"<p>Runtime representations with computed fields:</p> <ul> <li><code>InternalTopology</code> - Enriched topology</li> <li><code>InternalNode</code> - Node with resolved interfaces</li> <li><code>InternalInterface</code> - Interface with peer info</li> <li><code>InternalLink</code> - Link with interface references</li> </ul>"},{"location":"architecture/#template-system","title":"Template System","text":"<p>Templates are organized in <code>netloom/templates/</code>:</p> <pre><code>templates/\n\u251c\u2500\u2500 _base/\n\u2502   \u2514\u2500\u2500 _macros.j2       # Shared Jinja2 macros\n\u251c\u2500\u2500 networkd/            # systemd-networkd templates\n\u2502   \u251c\u2500\u2500 hostname.j2\n\u2502   \u251c\u2500\u2500 interface.network.j2\n\u2502   \u251c\u2500\u2500 routes.network.j2\n\u2502   \u2514\u2500\u2500 sysctl.conf.j2\n\u2514\u2500\u2500 services/\n    \u2514\u2500\u2500 services.list.j2\n</code></pre>"},{"location":"architecture/#template-context","title":"Template Context","text":"<p>Each template receives:</p> <ul> <li><code>node</code> - The internal node model</li> <li><code>topology</code> - The full internal topology</li> <li>Global macros from <code>_base/_macros.j2</code></li> </ul>"},{"location":"architecture/#output-mapping","title":"Output Mapping","text":"<p>Template filenames determine output paths:</p> Template Output <code>hostname.j2</code> <code>etc/hostname</code> <code>interface.network.j2</code> <code>etc/systemd/network/&lt;iface&gt;.network</code> <code>sysctl.conf.j2</code> <code>etc/sysctl.d/99-netloom.conf</code>"},{"location":"architecture/#virtualbox-integration","title":"VirtualBox Integration","text":"<p>NetLoom uses <code>VBoxManage</code> CLI for all VM operations:</p>"},{"location":"architecture/#linked-clones","title":"Linked Clones","text":"<p>VMs are created as linked clones from a golden snapshot:</p> <pre><code>VBoxManage clonevm \"Labs-Base\" --name \"R1\" --snapshot \"golden\" \\\n    --options link --register\n</code></pre> <p>Benefits:</p> <ul> <li>Fast creation (no full disk copy)</li> <li>Minimal disk usage</li> <li>Shared base image</li> </ul>"},{"location":"architecture/#config-drives","title":"Config-Drives","text":"<p>Each VM has a FAT-formatted VMDK attached as a secondary disk:</p> <pre><code>VBoxManage createmedium disk --filename \"R1-cfg.vmdk\" \\\n    --size 16 --format VMDK\n</code></pre> <p>The config-drive contains network configurations that the VM applies on boot.</p>"},{"location":"architecture/#internal-networks","title":"Internal Networks","text":"<p>Links are implemented as VirtualBox internal networks:</p> <pre><code>VBoxManage modifyvm \"R1\" --nic2 intnet --intnet2 \"lab-R1-R2\"\n</code></pre> <p>Each link gets a unique internal network name ensuring isolation.</p>"},{"location":"architecture/#extension-points","title":"Extension Points","text":""},{"location":"architecture/#custom-template-sets","title":"Custom Template Sets","text":"<p>Create a new directory in <code>templates/</code> with your templates:</p> <pre><code>templates/\n\u2514\u2500\u2500 my-templates/\n    \u251c\u2500\u2500 custom.conf.j2\n    \u2514\u2500\u2500 ...\n</code></pre> <p>Use with: <code>netloom --topology lab.yaml gen --templates my-templates</code></p>"},{"location":"architecture/#adding-controllers","title":"Adding Controllers","text":"<ol> <li>Create a new controller class inheriting from <code>BaseController</code></li> <li>Add a property in <code>Application</code> class</li> <li>Wire up CLI commands in <code>cli.py</code></li> </ol>"},{"location":"cli-reference/","title":"CLI Reference","text":"<p>Complete reference for all NetLoom commands and options.</p> <p>Tip</p> <p>Enable shell completion for faster command entry with tab completion.</p>"},{"location":"cli-reference/#global-options","title":"Global Options","text":"<p>All commands require the <code>--topology</code> option and accept these global options:</p> Option Type Default Description <code>--topology</code> Path required Path to topology YAML file <code>--workdir</code> Path <code>.labs_configs</code> Working directory for generated configs and artifacts <code>--basefolder</code> Path VirtualBox default VirtualBox VM base folder <code>--ova</code> Path - Path to base OVA (used on first init) <code>--base-vm</code> String <code>Labs-Base</code> Name for the imported base VM <code>--snapshot</code> String <code>golden</code> Snapshot name used for linked clones <code>-h, --help</code> - - Show help message"},{"location":"cli-reference/#commands","title":"Commands","text":""},{"location":"cli-reference/#init","title":"init","text":"<p>Import base OVA and create a golden snapshot.</p> <pre><code>netloom --topology lab.yaml --ova base.ova init\n</code></pre> <p>What it does:</p> <ol> <li>Imports the OVA file as a new VM (named by <code>--base-vm</code>)</li> <li>Creates a snapshot (named by <code>--snapshot</code>) for linked cloning</li> <li>Initializes the workdir structure</li> </ol> <p>Note</p> <p>Only run <code>init</code> once per base image. The base VM is reused across all topologies.</p>"},{"location":"cli-reference/#create","title":"create","text":"<p>Create linked clones for all topology nodes and attach empty config-drives.</p> <pre><code>netloom --topology lab.yaml create\n</code></pre> <p>What it does:</p> <ol> <li>Creates a linked clone for each node in the topology</li> <li>Configures VirtualBox internal networks for each link</li> <li>Attaches an empty config-drive ISO to each VM</li> </ol>"},{"location":"cli-reference/#gen","title":"gen","text":"<p>Generate configuration files for all nodes.</p> <pre><code>netloom --topology lab.yaml gen\n</code></pre> <p>Options:</p> Option Type Default Description <code>--templates</code> String <code>networkd</code> Template set name to use <p>What it does:</p> <ol> <li>Renders Jinja2 templates for each node based on topology config</li> <li>Generates networkd configs, hostname, sysctl settings, etc.</li> <li>Outputs to <code>&lt;workdir&gt;/configs/&lt;node&gt;/</code></li> </ol> <p>Available template sets:</p> <ul> <li><code>networkd</code> - systemd-networkd configuration (default)</li> </ul> <p>Use <code>list-templates</code> to see all available template sets.</p>"},{"location":"cli-reference/#attach","title":"attach","text":"<p>Copy generated configs into each node's config-drive.</p> <pre><code>netloom --topology lab.yaml attach\n</code></pre> <p>What it does:</p> <ol> <li>Mounts each VM's config-drive ISO</li> <li>Copies configs from <code>&lt;workdir&gt;/configs/&lt;node&gt;/</code> to the config-drive</li> <li>Unmounts the config-drive</li> </ol>"},{"location":"cli-reference/#start","title":"start","text":"<p>Start all topology VMs.</p> <pre><code>netloom --topology lab.yaml start\n</code></pre> <p>What it does:</p> <ol> <li>Starts each VM in headless mode</li> <li>VMs boot and apply configs from their config-drives</li> </ol>"},{"location":"cli-reference/#stop","title":"stop","text":"<p>Send ACPI shutdown signal to all topology VMs.</p> <pre><code>netloom --topology lab.yaml stop\n</code></pre> <p>What it does:</p> <ol> <li>Sends ACPI power button event to each VM</li> <li>VMs perform graceful shutdown</li> </ol>"},{"location":"cli-reference/#destroy","title":"destroy","text":"<p>Stop and remove all topology VMs.</p> <pre><code>netloom --topology lab.yaml destroy\n</code></pre> <p>Options:</p> Option Type Default Description <code>--all</code> Flag false Also destroy the base (golden) VM <p>What it does:</p> <ol> <li>Powers off all topology VMs</li> <li>Unregisters and deletes VM files</li> <li>With <code>--all</code>: also destroys the base VM</li> </ol> <p>Warning</p> <p>Using <code>--all</code> will require re-running <code>init</code> with the OVA for future deployments.</p>"},{"location":"cli-reference/#save","title":"save","text":"<p>Pull changed files from config-drive back to host.</p> <pre><code>netloom --topology lab.yaml save\n</code></pre> <p>What it does:</p> <ol> <li>Mounts each VM's config-drive</li> <li>Copies contents to <code>&lt;workdir&gt;/saved/&lt;node&gt;/</code></li> <li>Preserves any changes made inside the VM</li> </ol>"},{"location":"cli-reference/#restore","title":"restore","text":"<p>Restore last saved configs into staging area.</p> <pre><code>netloom --topology lab.yaml restore\n</code></pre> <p>What it does:</p> <ol> <li>Copies saved configs from <code>&lt;workdir&gt;/saved/&lt;node&gt;/</code></li> <li>Overwrites <code>&lt;workdir&gt;/configs/&lt;node&gt;/</code></li> <li>Ready for <code>attach</code> to deploy to VMs</li> </ol>"},{"location":"cli-reference/#list-templates","title":"list-templates","text":"<p>List available template sets.</p> <pre><code>netloom --topology lab.yaml list-templates\n</code></pre> <p>Output example:</p> <pre><code>Available template sets:\n  - networkd\n</code></pre>"},{"location":"cli-reference/#show","title":"show","text":"<p>Display topology information.</p> <pre><code>netloom --topology lab.yaml show\n</code></pre> <p>Output example:</p> <pre><code>Topology: My Lab (my-lab)\nA sample network topology\n\nNodes: 3\n  R1 (router)\n    eth1 [10.0.1.1/24] -&gt; R2\n    eth2 [192.168.1.1/24] -&gt; H1\n  R2 (router)\n    eth1 [10.0.1.2/24] -&gt; R1\n  H1 (host)\n    eth1 [192.168.1.10/24] -&gt; R1\n\nLinks: 2\n  R1/eth1 &lt;-&gt; R2/eth1\n  R1/eth2 &lt;-&gt; H1/eth1\n</code></pre>"},{"location":"cli-reference/#usage-examples","title":"Usage Examples","text":""},{"location":"cli-reference/#deploy-a-new-topology","title":"Deploy a New Topology","text":"<pre><code># First deployment with new base image\nnetloom --topology lab.yaml --ova base.ova init\nnetloom --topology lab.yaml create\nnetloom --topology lab.yaml gen\nnetloom --topology lab.yaml attach\nnetloom --topology lab.yaml start\n</code></pre>"},{"location":"cli-reference/#update-configurations","title":"Update Configurations","text":"<pre><code># After editing topology YAML\nnetloom --topology lab.yaml gen\nnetloom --topology lab.yaml attach\n# Reboot VMs or re-apply configs manually\n</code></pre>"},{"location":"cli-reference/#custom-workdir","title":"Custom Workdir","text":"<pre><code># Use a specific directory for this lab\nnetloom --topology lab.yaml --workdir ./lab1-work create\n</code></pre>"},{"location":"cli-reference/#multiple-topologies","title":"Multiple Topologies","text":"<pre><code># Each topology uses its own VMs but shares the base\nnetloom --topology lab1.yaml create\nnetloom --topology lab2.yaml create\n</code></pre>"},{"location":"configuration/","title":"Configuration","text":"<p>This document covers NetLoom's configuration options, workdir structure, and customization.</p>"},{"location":"configuration/#workdir-structure","title":"Workdir Structure","text":"<p>The working directory (default: <code>.labs_configs</code>) contains all generated artifacts:</p> <pre><code>.labs_configs/\n\u251c\u2500\u2500 configs/           # Generated configurations (ready for deployment)\n\u2502   \u251c\u2500\u2500 R1/\n\u2502   \u2502   \u251c\u2500\u2500 etc/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 hostname\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 sysctl.d/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 99-netloom.conf\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 systemd/\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 network/\n\u2502   \u2502   \u2502           \u251c\u2500\u2500 eth1.network\n\u2502   \u2502   \u2502           \u2514\u2500\u2500 eth2.network\n\u2502   \u2502   \u2514\u2500\u2500 _debug.json    # Debug info (when debug mode enabled)\n\u2502   \u251c\u2500\u2500 R2/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 saved/             # Configs pulled from VMs (after `save` command)\n\u2502   \u251c\u2500\u2500 R1/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 drives/            # Config-drive VMDKs\n    \u251c\u2500\u2500 R1-cfg.vmdk\n    \u251c\u2500\u2500 R2-cfg.vmdk\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"configuration/#configs","title":"configs/","text":"<p>Generated configuration files ready for deployment. Structure mirrors the target filesystem:</p> <ul> <li><code>etc/hostname</code> - Node hostname</li> <li><code>etc/sysctl.d/99-netloom.conf</code> - Kernel parameters</li> <li><code>etc/systemd/network/*.network</code> - networkd interface configs</li> </ul>"},{"location":"configuration/#saved","title":"saved/","text":"<p>Configurations pulled from running VMs using the <code>save</code> command. Preserves any manual changes made inside VMs.</p>"},{"location":"configuration/#drives","title":"drives/","text":"<p>Config-drive VMDK files attached to each VM. These are FAT-formatted virtual disks containing the node's configuration.</p>"},{"location":"configuration/#virtualbox-settings","title":"VirtualBox Settings","text":""},{"location":"configuration/#base-vm","title":"Base VM","text":"Option Default Description <code>--base-vm</code> <code>Labs-Base</code> Name for the imported base VM <code>--snapshot</code> <code>golden</code> Snapshot name for linked clones <code>--ova</code> - Path to base OVA (required for <code>init</code>) <code>--basefolder</code> VirtualBox default VM storage location"},{"location":"configuration/#vm-hardware","title":"VM Hardware","text":"<p>Configure in topology <code>defaults.vbox</code>:</p> <pre><code>defaults:\n  vbox:\n    paravirt_provider: kvm # Paravirtualization\n    chipset: ich9 # Chipset type\n    ioapic: true # I/O APIC\n    hpet: true # High Precision Event Timer\n</code></pre>"},{"location":"configuration/#network-adapters","title":"Network Adapters","text":"<ul> <li>NIC 1 - NAT (management, unchanged from base)</li> <li>NIC 2+ - Internal networks (topology links)</li> </ul> <p>Internal network names follow the pattern: <code>&lt;topology-id&gt;-&lt;nodeA&gt;-&lt;nodeB&gt;</code></p>"},{"location":"configuration/#template-customization","title":"Template Customization","text":""},{"location":"configuration/#available-template-sets","title":"Available Template Sets","text":"<p>List available templates:</p> <pre><code>netloom --topology lab.yaml list-templates\n</code></pre> <p>Built-in sets:</p> <ul> <li><code>networkd</code> - systemd-networkd configuration (default)</li> </ul>"},{"location":"configuration/#creating-custom-templates","title":"Creating Custom Templates","text":"<ol> <li>Create a new directory in <code>netloom/templates/</code>:</li> </ol> <pre><code>netloom/templates/\n\u2514\u2500\u2500 my-templates/\n    \u251c\u2500\u2500 custom-hostname.j2\n    \u2514\u2500\u2500 my-config.j2\n</code></pre> <ol> <li>Use in generation:</li> </ol> <pre><code>netloom --topology lab.yaml gen --templates my-templates\n</code></pre>"},{"location":"configuration/#template-variables","title":"Template Variables","text":"<p>Templates receive these variables:</p> Variable Type Description <code>node</code> InternalNode Current node being configured <code>topology</code> InternalTopology Full topology <p>Node properties:</p> <pre><code>{{ node.name }}              {# Node name #}\n{{ node.role }}              {# router, switch, host #}\n{{ node.interfaces }}        {# List of interfaces #}\n{{ node.sysctl }}            {# Merged sysctl settings #}\n{{ node.routing }}           {# Routing configuration #}\n{{ node.services }}          {# Services configuration #}\n</code></pre> <p>Interface properties:</p> <pre><code>{% for iface in node.interfaces %}\n{{ iface.name }}             {# eth1, eth2, etc. #}\n{{ iface.ip }}               {# IP in CIDR notation #}\n{{ iface.gateway }}          {# Gateway IP #}\n{{ iface.peer_node }}        {# Connected node name #}\n{{ iface.configured }}       {# Whether to generate config #}\n{% endfor %}\n</code></pre>"},{"location":"configuration/#output-path-mapping","title":"Output Path Mapping","text":"<p>Template filenames determine output locations:</p> Template Pattern Output Path <code>hostname.j2</code> <code>etc/hostname</code> <code>*.network.j2</code> <code>etc/systemd/network/&lt;name&gt;.network</code> <code>sysctl.conf.j2</code> <code>etc/sysctl.d/99-netloom.conf</code> <code>*.conf.j2</code> <code>etc/&lt;name&gt;.conf</code>"},{"location":"configuration/#shared-macros","title":"Shared Macros","text":"<p>Common macros are in <code>templates/_base/_macros.j2</code>:</p> <pre><code>{% import '_base/_macros.j2' as macros %}\n\n{{ macros.some_helper() }}\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>NetLoom respects standard VirtualBox environment variables:</p> Variable Description <code>VBOX_USER_HOME</code> VirtualBox configuration directory <code>VBOX_INSTALL_PATH</code> VirtualBox installation path"},{"location":"configuration/#debug-mode","title":"Debug Mode","text":"<p>Debug mode outputs additional information:</p> <ul> <li><code>_debug.json</code> files in each node's config directory</li> <li>Detailed console output during operations</li> </ul> <p>Debug mode is enabled by default during development.</p>"},{"location":"configuration/#multiple-topologies","title":"Multiple Topologies","text":"<p>You can run multiple topologies simultaneously:</p> <pre><code># Each topology uses its own VMs\nnetloom --topology lab1.yaml --workdir .lab1 create\nnetloom --topology lab2.yaml --workdir .lab2 create\n</code></pre> <p>Considerations:</p> <ul> <li>Use different workdirs to avoid conflicts</li> <li>All topologies share the same base VM</li> <li>Internal network names include topology ID for isolation</li> </ul>"},{"location":"configuration/#performance-tips","title":"Performance Tips","text":""},{"location":"configuration/#linked-clones","title":"Linked Clones","text":"<p>NetLoom uses linked clones by default:</p> <ul> <li>Pros: Fast creation, minimal disk usage</li> <li>Cons: Depends on base snapshot, slightly slower I/O</li> </ul>"},{"location":"configuration/#config-drive-size","title":"Config-Drive Size","text":"<p>Default config-drive size is 128 MB, sufficient for most configurations. Increase if needed for large config files.</p>"},{"location":"configuration/#parallel-operations","title":"Parallel Operations","text":"<p>VM operations are performed sequentially to avoid VirtualBox conflicts. For large topologies, consider:</p> <ul> <li>Splitting into smaller independent topologies</li> <li>Using the <code>--workdir</code> option for parallel development</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide walks you through installing NetLoom and deploying your first network topology.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before using NetLoom, ensure you have:</p> <ul> <li>Python 3.13+ - NetLoom requires Python 3.13 or later</li> <li>VirtualBox - Oracle VirtualBox for VM management</li> <li>Base OVA - A prepared Linux OVA image (see Preparing a Base Image)</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#using-uv-recommended","title":"Using uv (Recommended)","text":"<pre><code>uv tool install netloom\n</code></pre>"},{"location":"getting-started/#using-pip","title":"Using pip","text":"<pre><code>pip install netloom\n</code></pre>"},{"location":"getting-started/#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/wlix13/NetLoom.git\ncd NetLoom\nuv sync\n</code></pre>"},{"location":"getting-started/#your-first-topology","title":"Your First Topology","text":""},{"location":"getting-started/#1-create-a-topology-file","title":"1. Create a Topology File","text":"<p>Create a file named <code>lab.yaml</code>:</p> <pre><code>meta:\n  id: \"my-first-lab\"\n  name: \"My First Network Lab\"\n  description: \"A simple two-router topology\"\n\nlinks:\n  - endpoints: [\"R1\", \"R2\"]\n\nnodes:\n  - name: R1\n    role: router\n    interfaces:\n      - ip: \"10.0.1.1/24\"\n\n  - name: R2\n    role: router\n    interfaces:\n      - ip: \"10.0.1.2/24\"\n</code></pre>"},{"location":"getting-started/#2-initialize-the-environment","title":"2. Initialize the Environment","text":"<p>Import the base OVA and create a golden snapshot:</p> <pre><code>netloom --topology lab.yaml --ova base.ova init\n</code></pre> <p>This command:</p> <ul> <li>Imports the base OVA as <code>Labs-Base</code> VM</li> <li>Takes a <code>golden</code> snapshot for linked cloning</li> </ul> <p>Note</p> <p>You only need to run <code>init</code> once per base image. Subsequent topologies can reuse the same base VM.</p>"},{"location":"getting-started/#3-create-the-vms","title":"3. Create the VMs","text":"<p>Create linked clones for each node in the topology:</p> <pre><code>netloom --topology lab.yaml create\n</code></pre> <p>This creates VMs named after your topology nodes (R1, R2) as linked clones of the base VM.</p>"},{"location":"getting-started/#4-generate-configurations","title":"4. Generate Configurations","text":"<p>Generate network configurations for all nodes:</p> <pre><code>netloom --topology lab.yaml gen\n</code></pre> <p>Generated configs are stored in <code>.labs_configs/configs/&lt;node&gt;/</code> by default.</p>"},{"location":"getting-started/#5-attach-configurations","title":"5. Attach Configurations","text":"<p>Copy the generated configs to each VM's config-drive:</p> <pre><code>netloom --topology lab.yaml attach\n</code></pre>"},{"location":"getting-started/#6-start-the-topology","title":"6. Start the Topology","text":"<p>Start all VMs:</p> <pre><code>netloom --topology lab.yaml start\n</code></pre> <p>Your network lab is now running! You can access each VM through VirtualBox or SSH.</p>"},{"location":"getting-started/#complete-workflow","title":"Complete Workflow","text":"<p>Here's the typical workflow in one view:</p> <pre><code># First-time setup (once per base image)\nnetloom --topology lab.yaml --ova base.ova init\n\n# Deploy a topology\nnetloom --topology lab.yaml create\nnetloom --topology lab.yaml gen\nnetloom --topology lab.yaml attach\nnetloom --topology lab.yaml start\n\n# Make changes and redeploy configs\nnetloom --topology lab.yaml gen\nnetloom --topology lab.yaml attach\n\n# Save changes made inside VMs\nnetloom --topology lab.yaml save\n\n# Stop and destroy when done\nnetloom --topology lab.yaml stop\nnetloom --topology lab.yaml destroy\n</code></pre>"},{"location":"getting-started/#preparing-a-base-image","title":"Preparing a Base Image","text":"<p>NetLoom requires a base OVA with:</p> <ol> <li>Linux OS - Debian/Ubuntu recommended</li> <li>systemd-networkd - For network configuration</li> <li>Config-drive support - Mount point at <code>/mnt/config</code> or similar</li> <li>Optional: BIRD or FRR for routing scenarios</li> </ol> <p>The base image should:</p> <ul> <li>Have a single network interface (eth0) for management</li> <li>Support additional interfaces (eth1, eth2, ...) for topology links</li> <li>Auto-apply configs from the config-drive on boot</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about all available CLI Commands</li> <li>Explore the Topology Schema for advanced configurations</li> <li>Understand the Architecture for customization</li> </ul>"},{"location":"shell-completion/","title":"Shell Completion","text":"<p>NetLoom supports tab completion for bash, zsh, and fish shells.</p>"},{"location":"shell-completion/#installation","title":"Installation","text":""},{"location":"shell-completion/#automatic-recommended","title":"Automatic (Recommended)","text":"<pre><code>netloom install-completion --install bash\nnetloom install-completion --install zsh\nnetloom install-completion --install fish\n</code></pre> <p>This automatically adds the completion script to your shell configuration file.</p>"},{"location":"shell-completion/#manual","title":"Manual","text":"<p>Add the appropriate line to your shell config:</p> <p>Bash (<code>~/.bashrc</code>):</p> <pre><code>eval \"$(_NETLOOM_COMPLETE=bash_source netloom)\"\n</code></pre> <p>Zsh (<code>~/.zshrc</code>):</p> <pre><code>eval \"$(_NETLOOM_COMPLETE=zsh_source netloom)\"\n</code></pre> <p>Fish (<code>~/.config/fish/config.fish</code>):</p> <pre><code>eval (env _NETLOOM_COMPLETE=fish_source netloom)\n</code></pre> <p>Then reload your shell: <code>source ~/.bashrc</code> (or equivalent).</p>"},{"location":"shell-completion/#usage","title":"Usage","text":"<p>Press <code>Tab</code> to complete commands, options, and file paths:</p> <pre><code>netloom &lt;TAB&gt;              # Shows all commands\nnetloom --&lt;TAB&gt;            # Shows all options\nnetloom --topology &lt;TAB&gt;   # Completes file paths\n</code></pre>"},{"location":"shell-completion/#troubleshooting","title":"Troubleshooting","text":"<p>If completion doesn't work:</p> <ol> <li>Restart your terminal or run <code>source ~/.bashrc</code> (or equivalent)</li> <li>Verify the completion line exists in your shell config file</li> <li>Check you're using the correct shell: <code>echo $SHELL</code></li> </ol>"},{"location":"topology-schema/","title":"Topology Schema Reference","text":"<p>This document describes the YAML schema for defining network topologies in NetLoom.</p>"},{"location":"topology-schema/#overview","title":"Overview","text":"<p>A topology file has four main sections:</p> <pre><code>meta:        # Required - Topology metadata\n  id: \"lab-id\"\n  name: \"Lab Name\"\n\ndefaults:    # Optional - Global defaults for all nodes\n  ip_forwarding: false\n\nlinks:       # Required - Physical connections between nodes\n  - endpoints: [\"A\", \"B\"]\n\nnodes:       # Required - Node definitions\n  - name: A\n    role: router\n</code></pre>"},{"location":"topology-schema/#meta","title":"Meta","text":"<p>Topology metadata. Required.</p> Field Type Required Description <code>id</code> string Yes Unique identifier for the topology <code>name</code> string Yes Human-readable name <code>description</code> string No Optional description <pre><code>meta:\n  id: \"campus-network\"\n  name: \"Campus Network Lab\"\n  description: \"Multi-site campus network with OSPF routing\"\n</code></pre>"},{"location":"topology-schema/#defaults","title":"Defaults","text":"<p>Global defaults applied to all nodes. Optional.</p> Field Type Default Description <code>ip_forwarding</code> boolean <code>false</code> Enable IP forwarding on all nodes <code>sysctl</code> object - Global kernel parameters <code>vbox</code> object - VirtualBox VM settings"},{"location":"topology-schema/#sysctl","title":"sysctl","text":"<p>Kernel parameters applied to all nodes:</p> <pre><code>defaults:\n  sysctl:\n    net.core.somaxconn: 1024\n    net.ipv4.tcp_syncookies: 1\n</code></pre>"},{"location":"topology-schema/#vbox","title":"vbox","text":"<p>VirtualBox-specific VM settings:</p> Field Type Default Description <code>paravirt_provider</code> string <code>kvm</code> Paravirtualization provider: <code>default</code>, <code>legacy</code>, <code>minimal</code>, <code>hyperv</code>, <code>kvm</code>, <code>none</code> <code>chipset</code> string <code>ich9</code> Chipset type: <code>piix3</code>, <code>ich9</code> <code>ioapic</code> boolean <code>true</code> Enable I/O APIC <code>hpet</code> boolean <code>true</code> Enable High Precision Event Timer <pre><code>defaults:\n  vbox:\n    paravirt_provider: kvm\n    chipset: ich9\n</code></pre>"},{"location":"topology-schema/#links","title":"Links","text":"<p>Physical connections between nodes. Required.</p> <p>Each link connects exactly two nodes. The order of links determines interface assignment (eth1, eth2, etc.).</p> Field Type Description <code>endpoints</code> array[2] Exactly two node names <pre><code>links:\n  - endpoints: [\"R1\", \"R2\"]    # R1.eth1 &lt;-&gt; R2.eth1\n  - endpoints: [\"R2\", \"R3\"]    # R2.eth2 &lt;-&gt; R3.eth1\n  - endpoints: [\"R1\", \"S1\"]    # R1.eth2 &lt;-&gt; S1.eth1\n</code></pre> <p>Interface Assignment</p> <p>Interfaces are assigned in order of link appearance. The first link for a node creates <code>eth1</code>, the second creates <code>eth2</code>, and so on.</p>"},{"location":"topology-schema/#nodes","title":"Nodes","text":"<p>Node definitions. Required.</p> Field Type Default Description <code>name</code> string required Unique node name <code>role</code> string <code>host</code> Node role: <code>router</code>, <code>switch</code>, <code>host</code> <code>sysctl</code> object - Node-specific kernel parameters <code>interfaces</code> array - Interface configurations <code>bridge</code> object - Bridge configuration (for switches) <code>routing</code> object - Routing daemon configuration <code>services</code> object - Service configurations <code>commands</code> array - Raw shell commands"},{"location":"topology-schema/#node-roles","title":"Node Roles","text":"<ul> <li>router - L3 device with IP forwarding, may run routing protocols</li> <li>switch - L2 device with bridging</li> <li>host - End device (workstation, server)</li> </ul> <pre><code>nodes:\n  - name: R1\n    role: router\n\n  - name: SW1\n    role: switch\n\n  - name: PC1\n    role: host\n</code></pre>"},{"location":"topology-schema/#interfaces","title":"interfaces","text":"<p>Interface configurations. Order matches link assignment order.</p> Field Type Default Description <code>ip</code> string - IP address in CIDR notation (e.g., <code>10.0.1.1/24</code>) <code>gateway</code> string - Default gateway IP <code>configured</code> boolean <code>true</code> If <code>false</code>, no config file is generated <pre><code>interfaces:\n  - ip: \"10.0.1.1/24\"           # eth1\n  - ip: \"10.0.2.1/24\"           # eth2\n    gateway: \"10.0.2.254\"\n  - configured: false           # eth3 - unmanaged\n</code></pre>"},{"location":"topology-schema/#bridge","title":"bridge","text":"<p>Bridge configuration for switch nodes.</p> Field Type Default Description <code>name</code> string <code>br0</code> Bridge interface name <code>stp</code> boolean <code>false</code> Enable Spanning Tree Protocol <code>configured</code> boolean <code>true</code> If <code>false</code>, no config file is generated <pre><code>- name: SW1\n  role: switch\n  bridge:\n    name: br0\n    stp: true\n  interfaces:\n    - configured: false  # Managed by bridge\n    - configured: false\n</code></pre>"},{"location":"topology-schema/#routing","title":"routing","text":"<p>Routing daemon configuration.</p> Field Type Default Description <code>engine</code> string - Routing daemon: <code>bird</code>, <code>frr</code>, <code>none</code> <code>router_id</code> string - Router ID (usually an IP) <code>static</code> array - Static routes <code>ospf</code> object - OSPF configuration <code>configured</code> boolean <code>true</code> If <code>false</code>, no config file is generated"},{"location":"topology-schema/#static-routes","title":"Static Routes","text":"<pre><code>routing:\n  engine: bird\n  static:\n    - \"10.0.0.0/8 via 192.168.1.1\"\n    - \"0.0.0.0/0 via 10.0.1.254\"\n</code></pre>"},{"location":"topology-schema/#ospf-configuration","title":"OSPF Configuration","text":"Field Type Default Description <code>enabled</code> boolean <code>false</code> Enable OSPF <code>areas</code> array - OSPF area definitions <p>OSPF Area:</p> Field Type Default Description <code>id</code> string <code>0.0.0.0</code> Area ID <code>interfaces</code> array - Interfaces in this area <pre><code>routing:\n  engine: bird\n  router_id: \"192.168.1.1\"\n  ospf:\n    enabled: true\n    areas:\n      - id: \"0.0.0.0\"\n        interfaces: [\"eth1\", \"eth2\"]\n      - id: \"0.0.0.1\"\n        interfaces: [\"eth3\"]\n</code></pre>"},{"location":"topology-schema/#services","title":"services","text":"<p>Service configurations.</p> Field Type Description <code>http_server</code> integer HTTP server port <code>wireguard</code> object WireGuard VPN configuration <code>firewall</code> object Firewall configuration"},{"location":"topology-schema/#wireguard","title":"WireGuard","text":"Field Type Description <code>private_key</code> string WireGuard private key <code>listen_port</code> integer UDP listen port <code>address</code> string Interface IP address <code>peers</code> array Peer configurations <p>WireGuard Peer:</p> Field Type Description <code>public_key</code> string Peer's public key <code>allowed_ips</code> string Allowed IP ranges <code>endpoint</code> string Peer endpoint (IP:port) <pre><code>services:\n  wireguard:\n    private_key: \"...\"\n    listen_port: 51820\n    address: \"10.200.0.1/24\"\n    peers:\n      - public_key: \"...\"\n        allowed_ips: \"10.200.0.2/32\"\n        endpoint: \"192.168.1.2:51820\"\n</code></pre>"},{"location":"topology-schema/#firewall","title":"Firewall","text":"Field Type Description <code>impl</code> string Firewall implementation: <code>nftables</code> <code>rules</code> array Firewall rules <p>Firewall Rule:</p> Field Type Description <code>action</code> string Rule action: <code>accept</code>, <code>drop</code>, <code>reject</code> <code>src</code> string Source IP/network <code>dst</code> string Destination IP/network <code>proto</code> string Protocol (tcp, udp, icmp) <code>dport</code> integer Destination port <pre><code>services:\n  firewall:\n    impl: nftables\n    rules:\n      - action: accept\n        proto: tcp\n        dport: 22\n      - action: accept\n        proto: tcp\n        dport: 80\n      - action: drop\n        src: \"0.0.0.0/0\"\n</code></pre>"},{"location":"topology-schema/#commands","title":"commands","text":"<p>Raw shell commands executed on the node. Use for edge cases not covered by other options.</p> <pre><code>commands:\n  - \"systemctl enable bird\"\n  - \"echo 'custom config' &gt; /etc/custom.conf\"\n</code></pre>"},{"location":"topology-schema/#complete-example","title":"Complete Example","text":"<pre><code>meta:\n  id: \"enterprise-lab\"\n  name: \"Enterprise Network Lab\"\n  description: \"Multi-router enterprise network with OSPF\"\n\ndefaults:\n  ip_forwarding: true\n  sysctl:\n    net.core.somaxconn: 1024\n\nlinks:\n  - endpoints: [\"R1\", \"R2\"]\n  - endpoints: [\"R2\", \"R3\"]\n  - endpoints: [\"R1\", \"SW1\"]\n  - endpoints: [\"SW1\", \"H1\"]\n  - endpoints: [\"SW1\", \"H2\"]\n\nnodes:\n  - name: R1\n    role: router\n    interfaces:\n      - ip: \"10.0.12.1/24\"\n      - ip: \"10.0.1.1/24\"\n    routing:\n      engine: bird\n      router_id: \"1.1.1.1\"\n      ospf:\n        enabled: true\n        areas:\n          - id: \"0.0.0.0\"\n            interfaces: [\"eth1\", \"eth2\"]\n\n  - name: R2\n    role: router\n    interfaces:\n      - ip: \"10.0.12.2/24\"\n      - ip: \"10.0.23.1/24\"\n    routing:\n      engine: bird\n      router_id: \"2.2.2.2\"\n      ospf:\n        enabled: true\n        areas:\n          - id: \"0.0.0.0\"\n            interfaces: [\"eth1\", \"eth2\"]\n\n  - name: R3\n    role: router\n    interfaces:\n      - ip: \"10.0.23.2/24\"\n    routing:\n      engine: frr\n      router_id: \"3.3.3.3\"\n      static:\n        - \"0.0.0.0/0 via 10.0.23.1\"\n\n  - name: SW1\n    role: switch\n    bridge:\n      name: br0\n      stp: true\n    interfaces:\n      - configured: false\n      - configured: false\n      - configured: false\n\n  - name: H1\n    role: host\n    interfaces:\n      - ip: \"10.0.1.10/24\"\n        gateway: \"10.0.1.1\"\n    services:\n      http_server: 8080\n      firewall:\n        impl: nftables\n        rules:\n          - action: accept\n            proto: tcp\n            dport: 8080\n          - action: accept\n            proto: icmp\n          - action: drop\n            src: \"0.0.0.0/0\"\n\n  - name: H2\n    role: host\n    interfaces:\n      - ip: \"10.0.1.20/24\"\n        gateway: \"10.0.1.1\"\n</code></pre>"}]}